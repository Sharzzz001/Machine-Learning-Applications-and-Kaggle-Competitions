{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import jinja2\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, roc_auc_score, f1_score, accuracy_score\n",
    "import plotly.express as px\n",
    "\n",
    "from lightgbm import LGBMClassifier, log_evaluation, LGBMRegressor, train\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3994318 entries, 0 to 3694317\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   id                    int64  \n",
      " 1   Brand                 object \n",
      " 2   Material              object \n",
      " 3   Size                  object \n",
      " 4   Compartments          float64\n",
      " 5   Laptop Compartment    object \n",
      " 6   Waterproof            object \n",
      " 7   Style                 object \n",
      " 8   Color                 object \n",
      " 9   Weight Capacity (kg)  float64\n",
      " 10  Price                 float64\n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 365.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df1 = pd.read_csv('training_extra.csv')\n",
    "# df.info()\n",
    "# merge both df and df1\n",
    "df = pd.concat([df, df1], axis=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                           0\n",
      "Brand                   126758\n",
      "Material                110962\n",
      "Size                     87785\n",
      "Compartments                 0\n",
      "Laptop Compartment       98533\n",
      "Waterproof               94324\n",
      "Style                   104180\n",
      "Color                   133617\n",
      "Weight Capacity (kg)      1808\n",
      "Price                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print NA in df\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X = df.drop(columns=['Price','id'], axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state=42, test_size = 0.2)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "del X_train, y_train, X, y, df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch GPU available:  True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print('Torch GPU available: ',torch.cuda.is_available())  # Should be True\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250213_193116\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.12.9\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          16\n",
      "Memory Avail:       1.13 GB / 15.71 GB (7.2%)\n",
      "Disk Space Avail:   424.41 GB / 931.50 GB (45.6%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 75s of the 300s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-02-14 01:01:25,811\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"d:\\Sharan\\College\\Kaggle Competitions\\S5E2 Backpack Prediction\\AutogluonModels\\ag-20250213_193116\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Beginning AutoGluon training ... Time limit = 58s\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m AutoGluon will save models to \"d:\\Sharan\\College\\Kaggle Competitions\\S5E2 Backpack Prediction\\AutogluonModels\\ag-20250213_193116\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Train Data Rows:    2840403\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Train Data Columns: 9\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Label Column:       Price\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tAvailable Memory:                    1930.77 MB\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tTrain Data (Original)  Memory Usage: 1056.46 MB (54.7% of available memory)\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tWarning: Data size prior to feature transformation consumes 54.7% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\t('float', [])  : 2 | ['Compartments', 'Weight Capacity (kg)']\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\t('object', []) : 7 | ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', ...]\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\t('category', []) : 7 | ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', ...]\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\t('float', [])    : 2 | ['Compartments', 'Weight Capacity (kg)']\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t20.3s = Fit runtime\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t9 features in original data used to generate 9 features in processed data.\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tTrain Data (Processed) Memory Usage: 62.31 MB (2.6% of available memory)\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Data preprocessing and feature engineering runtime = 21.77s ...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 24.46s of the 36.68s of remaining time.\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tWarning: Not enough memory to safely train model. Estimated to require 0.368 GB out of 1.134 GB available memory (32.450%)... (20.000% of avail memory is the max safe size)\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.67 to avoid the error)\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tNot enough memory to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 19.17s of the 31.40s of remaining time.\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tWarning: Not enough memory to safely train model. Estimated to require 0.368 GB out of 1.123 GB available memory (32.771%)... (20.000% of avail memory is the max safe size)\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.69 to avoid the error)\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tNot enough memory to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 18.33s of the 30.56s of remaining time.\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 1 folds in parallel instead (Estimated 62.33% memory usage per fold, 62.33%/80.00% total).\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=0, memory=62.33%)\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\tSwitching to pseudo sequential ParallelFoldFittingStrategy to avoid Python memory leakage.\n",
      "\u001b[36m(_dystack pid=24176)\u001b[0m \t\tOverrule this behavior by setting fold_fitting_strategy to 'sequential_local' in ag_args_ensemble when when calling `predictor.fit`\n"
     ]
    }
   ],
   "source": [
    "# Write autogluon regressor code here for df\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "train_data = TabularDataset(train)\n",
    "test_data = TabularDataset(test)\n",
    "\n",
    "predictor = TabularPredictor(label='Price', problem_type='regression', eval_metric='root_mean_squared_error').fit(train_data,presets='best_quality',time_limit=60*5)\n",
    "# predictions = predictor.predict(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
